{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Edge Fluency Classifier - Inference Demo\n",
                "\n",
                "This notebook demonstrates how to load a trained model and perform inference on speech clips from the Speechocean762 dataset.\n",
                "\n",
                "**Prerequisites:**\n",
                "1.  Ensure you have run `make setup` to install dependencies.\n",
                "2.  Ensure you have run `make download` and `make features` to prepare data.\n",
                "3.  Ensure you have run `make train_teacher` (or other training targets) to generate checkpoints."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import json\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import IPython.display as ipd\n",
                "\n",
                "# Add src to path\n",
                "project_root = Path(os.getcwd()).parent\n",
                "if str(project_root / \"src\") not in sys.path:\n",
                "    sys.path.append(str(project_root / \"src\"))\n",
                "\n",
                "from utils.config import load_config\n",
                "from models.mlp import build_mlp\n",
                "from features.extractor import extract_features\n",
                "from audio.processing import load_audio, preprocess"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Configuration and Model\n",
                "We load the global configuration and the trained MLP model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load config\n",
                "cfg = load_config(\"config/default.yaml\")\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "\n",
                "# Load label map\n",
                "label_map_path = Path(\"experiments/exports/label_map.json\")\n",
                "if not label_map_path.exists():\n",
                "    # Fallback if export hasn't run\n",
                "    label_map = {\"poor\": 0, \"moderate\": 1, \"good\": 2}\n",
                "else:\n",
                "    with open(label_map_path) as f:\n",
                "        label_map = json.load(f)\n",
                "\n",
                "id2label = {v: k for k, v in label_map.items()}\n",
                "print(f\"Label Map: {label_map}\")\n",
                "\n",
                "# Determine input dimension (from config or dummy)\n",
                "# Typically 30000 for 1-5s clips with default feature settings\n",
                "input_dim = 30000 \n",
                "\n",
                "# Initialize Model\n",
                "model_name = cfg[\"training\"].get(\"model\", \"mlp_small\")\n",
                "model = build_mlp(model_name, input_dim, len(label_map), cfg[\"models\"])\n",
                "model.to(device)\n",
                "\n",
                "# Load Checkpoint\n",
                "ckpt_path = Path(\"experiments/checkpoints\") / f\"{model_name}.pt\"\n",
                "if ckpt_path.exists():\n",
                "    state = torch.load(ckpt_path, map_location=device)\n",
                "    model.load_state_dict(state[\"state_dict\"])\n",
                "    print(f\"Loaded checkpoint from {ckpt_path}\")\n",
                "    model.eval()\n",
                "else:\n",
                "    print(f\"WARNING: Checkpoint not found at {ckpt_path}. Using random weights.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Sample Data\n",
                "We pick a sample from the test set to evaluate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_manifest = Path(\"experiments/manifests/test.csv\")\n",
                "if test_manifest.exists():\n",
                "    df = pd.read_csv(test_manifest)\n",
                "    sample = df.iloc[0]\n",
                "    audio_path = sample[\"path\"]\n",
                "    print(f\"Selected sample: {audio_path}\")\n",
                "    print(f\"True Label: {sample['label']}\")\n",
                "    print(f\"Text: {sample.get('text', 'N/A')}\")\n",
                "    \n",
                "    # Play Audio\n",
                "    ipd.display(ipd.Audio(audio_path))\n",
                "else:\n",
                "    print(\"Test manifest not found. Please run `make download` and `make features`.\")\n",
                "    audio_path = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Inference\n",
                "Preprocess the audio, extract features, and predict the fluency score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict(path, model, cfg):\n",
                "    if not path:\n",
                "        return\n",
                "        \n",
                "    # 1. Preprocess (load, resample, trim)\n",
                "    wav = preprocess(\n",
                "        path,\n",
                "        sample_rate=cfg[\"data\"][\"sample_rate\"],\n",
                "        min_sec=cfg[\"data\"][\"clip_seconds\"][0],\n",
                "        max_sec=cfg[\"data\"][\"clip_seconds\"][1]\n",
                "    )\n",
                "    \n",
                "    # 2. Extract Features\n",
                "    feats = extract_features(wav, cfg[\"data\"][\"sample_rate\"], cfg[\"features\"])\n",
                "    \n",
                "    # 3. Flatten and Normalize (Simple CMVN if available, else raw)\n",
                "    # Note: In production, load global CMVN stats. Here we just flatten.\n",
                "    x = feats.flatten()\n",
                "    \n",
                "    # Pad/Truncate to expected input_dim\n",
                "    if len(x) < input_dim:\n",
                "        x = np.pad(x, (0, input_dim - len(x)))\n",
                "    else:\n",
                "        x = x[:input_dim]\n",
                "        \n",
                "    # 4. Inference\n",
                "    x_tensor = torch.from_numpy(x).float().unsqueeze(0).to(device)\n",
                "    with torch.no_grad():\n",
                "        logits = model(x_tensor)\n",
                "        probs = torch.softmax(logits, dim=1)\n",
                "        pred_idx = torch.argmax(probs).item()\n",
                "        \n",
                "    return id2label[pred_idx], probs[0].cpu().numpy()\n",
                "\n",
                "if audio_path:\n",
                "    pred_label, probabilities = predict(audio_path, model, cfg)\n",
                "    print(f\"\\nPredicted Label: {pred_label.upper()}\")\n",
                "    print(f\"Confidence: {probabilities[label_map[pred_label]]:.4f}\")\n",
                "    print(f\"Class Probabilities: {probabilities}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}